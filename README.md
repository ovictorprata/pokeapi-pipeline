# Pipeline Automatizado de Extra√ß√£o, Transforma√ß√£o e Relat√≥rio com PokeAPI

Este projeto foi desenvolvido como parte de um teste t√©cnico para avaliar habilidades em extra√ß√£o, transforma√ß√£o e an√°lise de dados utilizando Python e pandas. O objetivo √© consumir dados da PokeAPI, process√°-los, gerar relat√≥rios e visualiza√ß√µes, e automatizar o processo em um pipeline eficiente.

## Estrutura de Diret√≥rios

‚îú‚îÄ‚îÄ Dockerfile # Arquivo de configura√ß√£o para a cria√ß√£o de imagem Docker

‚îú‚îÄ‚îÄ logs # Diret√≥rio de logs gerados pelo pipeline
‚îî‚îÄ‚îÄ pipeline.log # Log de execu√ß√£o do pipeline
‚îú‚îÄ‚îÄ README.md # Este arquivo de documenta√ß√£o
‚îú‚îÄ‚îÄ reports # Diret√≥rio onde os relat√≥rios e gr√°ficos s√£o salvos
‚îú‚îÄ‚îÄ requirements.txt # Arquivo com as depend√™ncias do projeto
‚îú‚îÄ‚îÄ src # C√≥digo fonte do projeto
‚îÇ‚îú‚îÄ‚îÄ analyze_data.py # C√≥digo para an√°lise estat√≠stica e gera√ß√£o de relat√≥rios ‚îÇ
‚îú‚îÄ‚îÄ data_extraction.py # C√≥digo para extra√ß√£o de dados da PokeAPI ‚îÇ
‚îú‚îÄ‚îÄ data_transformation.py # C√≥digo para transforma√ß√£o e categoriza√ß√£o dos dados ‚îÇ
‚îú‚îÄ‚îÄ pipeline.py # Orquestra√ß√£o do pipeline ‚îÇ
‚îî‚îÄ‚îÄ pycache # Arquivos compilados do Python
‚îî‚îÄ‚îÄ utils # Fun√ß√µes auxiliares e utilit√°rias
‚îú‚îÄ‚îÄ pycache # Arquivos compilados do Python
‚îî‚îÄ‚îÄ utils.py # Fun√ß√µes auxiliares para o processo

## Requisitos

O projeto depende das seguintes bibliotecas Python:

- `pandas` - Para manipula√ß√£o e transforma√ß√£o de dados.
- `matplotlib` ou `seaborn` - Para visualiza√ß√£o de dados.
- `requests` - Para consumir dados da PokeAPI.
- `logging` - Para gerar logs do pipeline.

Instale as depend√™ncias executando:

```bash
pip install -r requirements.txt
```

## Como Executar

- Extra√ß√£o de Dados: O script de extra√ß√£o ir√° consultar a PokeAPI para coletar dados dos Pok√©mon.
- Transforma√ß√£o de Dados: Os dados extra√≠dos ser√£o transformados, categorizados e organizados para an√°lise.
- An√°lise e Relat√≥rio: O script gerar√° um relat√≥rio consolidado com tabelas e gr√°ficos.
- Execu√ß√£o do Pipeline: Para rodar o pipeline completo, execute o script pipeline.py.

## Passo a Passo

Suba a imagem Docker (opcional):

Para construir e rodar o container Docker, use os seguintes comandos:

```bash
docker build -t pokemon-pipeline .
docker run pokemon-pipeline
```

Execute o script principal:

Se preferir rodar localmente, basta executar o script pipeline.py:

```bash
python src/pipeline.py
```

O script ir√°:

1. Extrair os dados da PokeAPI.
2. Transformar os dados com base na categoriza√ß√£o de experi√™ncia.
3. Gerar um relat√≥rio contendo tabelas e gr√°ficos.
4. Salvar o relat√≥rio em formato CSV e o gr√°fico em formato PNG na pasta reports.
5. Logs: Durante a execu√ß√£o do pipeline, os logs ser√£o registrados no arquivo logs/pipeline.log. O uso da biblioteca logging permite o acompanhamento do progresso do pipeline, incluindo eventuais falhas ou erros no processo.

## Como Executar com Docker

#### Dockerfile

O Dockerfile est√° configurado para permitir que o pipeline seja executado de forma consistente em qualquer ambiente. Ele instala todas as depend√™ncias necess√°rias e configura o ambiente de execu√ß√£o.

Se preferir rodar o pipeline em um ambiente Docker, basta seguir os seguintes passos:

#### Passo 1: Construir a Imagem Docker

Primeiro, construa a imagem Docker utilizando o comando abaixo:

```bash
docker build -t pokemon-pipeline .
```

#### Passo 2: Rodar o Container Docker

Depois de construir a imagem, voc√™ pode executar o pipeline com o comando:

```bash
docker run -v $(pwd)/reports:/app/reports pokemon-pipeline
```

O comando acima usa a flag -v para mapear a pasta reports do seu sistema local para a pasta reports dentro do container Docker. Se a pasta reports n√£o existir no seu sistema local, ela ser√° criada automaticamente.

#### O que Acontece ao Rodar com Docker?

**Relat√≥rios e Gr√°ficos:** Ao rodar o pipeline no Docker, todos os relat√≥rios gerados (em formato CSV) e gr√°ficos (em formato PNG) ser√£o salvos na pasta reports/ dentro do container. Gra√ßas ao mapeamento do volume (-v $(pwd)/reports:/app/reports), esses arquivos ser√£o automaticamente transferidos para a pasta reports/ do seu sistema local, criando a pasta se necess√°rio.

**Logs:** O progresso do pipeline e qualquer erro ser√£o registrados no arquivo de log logs/pipeline.log dentro do container. Este arquivo tamb√©m ficar√° acess√≠vel em seu sistema local, dentro da pasta logs/.

üí° Ao final da execu√ß√£o, voc√™ encontrar√° os seguintes arquivos:

- Relat√≥rio CSV gerado com as tabelas de Pok√©mon e an√°lises.
- Gr√°fico gerado mostrando a distribui√ß√£o dos Pok√©mon por tipo, salvo como PNG.

‚ö†Ô∏è **Observa√ß√µes**

- N√£o √© necess√°rio criar a pasta reports manualmente, pois ela ser√° criada automaticamente se n√£o existir no seu diret√≥rio local.
- Caso deseje rodar o pipeline sem Docker, basta executar o script src/pipeline.py diretamente, conforme instru√ß√µes anteriores.

## Funcionalidades do Pipeline

### Extra√ß√£o de Dados:

Acessar a PokeAPI para obter informa√ß√µes sobre 100 Pok√©mons. Para cada Pok√©mon, o pipeline extrai detalhes adicionais de:

- ID
- Nome
- Experi√™ncia base
- Tipos
- HP
- Ataque

### Transforma√ß√£o de Dados:

1. **Categoriza√ß√£o**
   Categoriza√ß√£o dos Pok√©mon em tr√™s grupos: "Fraco", "M√©dio" e "Forte", baseado na experi√™ncia base.
   | Experi√™ncia base | Categoria |
   | ---------------- | --------- |
   | < 50 | Fraco |
   | Entre 50 e 100 | M√©dio |
   | > 100 | Forte |

2. **Transforma√ß√µes de Tipos**
   Gera a contagem de Pok√©mon por tipo e, em seguida, cria um gr√°fico de barras visualizando a distribui√ß√£o de Pok√©mon em cada tipo.

3. **An√°lise Estat√≠stica**
   3.1. C√°lculo da m√©dia de ataque, defesa e HP por tipo.
   3.2. Exibi√ß√£o dos 5 Pok√©mon com maior experi√™ncia base.

4. **Relat√≥rio e Exporta√ß√£o**
   4.1. Gera√ß√£o de relat√≥rio em formato CSV com as tabelas e gr√°ficos de an√°lise.
   4.2. Gera√ß√£o de gr√°fico de distribui√ß√£o dos Pok√©mon por tipo.

## Notas Finais

- O pipeline √© modularizado para facilitar a manuten√ß√£o e adapta√ß√£o.
- Caso ocorram falhas nas requisi√ß√µes √† API, erros ser√£o tratados e registrados nos logs.
- O relat√≥rio e os gr√°ficos gerados podem ser encontrados na pasta reports.
